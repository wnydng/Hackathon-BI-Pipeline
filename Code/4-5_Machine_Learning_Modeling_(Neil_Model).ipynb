{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN5wjOefu8CuvxvcOQeBPUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wnydng/Hackathon-BI-Pipeline/blob/neil/1er_jet_MLmodel_dataset_hackhathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qKxy2hCJJqvo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import average_precision_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Chargement des fichiers"
      ],
      "metadata": {
        "id": "2iagE84sefWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transactions_train = pd.read_csv(\"transactions_train.csv\")\n",
        "cards_data = pd.read_csv(\"cards_data.csv\")\n",
        "users_data = pd.read_csv(\"users_data.csv\")\n",
        "\n",
        "with open(\"train_fraud_labels.json\", \"r\") as f:\n",
        "    labels_json = json.load(f)\n",
        "labels_dict = labels_json.get(\"target\", labels_json)\n",
        "labels_df = pd.DataFrame(list(labels_dict.items()), columns=[\"transaction_id\", \"fraud_label\"])\n",
        "\n",
        "with open(\"mcc_codes.json\", \"r\") as f:\n",
        "    mcc_codes = json.load(f)\n",
        "mcc_df = pd.DataFrame(list(mcc_codes.items()), columns=[\"mcc\", \"mcc_description\"])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SdLCQT2PL1rM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Nettoyage de base"
      ],
      "metadata": {
        "id": "gguheWRQetTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_dollar(x):\n",
        "    if isinstance(x, str):\n",
        "        return float(x.replace(\"$\", \"\").replace(\",\", \"\"))\n",
        "    return x\n",
        "\n",
        "# Transactions\n",
        "transactions_train[\"amount\"] = transactions_train[\"amount\"].apply(clean_dollar)\n",
        "transactions_train[\"zip\"] = transactions_train[\"zip\"].fillna(0).astype(int)\n",
        "transactions_train[\"mcc\"] = transactions_train[\"mcc\"].astype(str)\n",
        "\n",
        "# Labels\n",
        "labels_df[\"transaction_id\"] = labels_df[\"transaction_id\"].astype(int)\n",
        "labels_df[\"fraud_label\"] = labels_df[\"fraud_label\"].map({\"Yes\": 1, \"No\": 0})\n",
        "\n",
        "# Cartes\n",
        "cards_data[\"credit_limit\"] = cards_data[\"credit_limit\"].apply(clean_dollar)\n",
        "cards_data[\"acct_open_date\"] = pd.to_datetime(cards_data[\"acct_open_date\"], errors=\"coerce\")\n",
        "\n",
        "# Utilisateurs\n",
        "users_data[\"yearly_income\"] = users_data[\"yearly_income\"].apply(clean_dollar)\n",
        "users_data[\"total_debt\"] = users_data[\"total_debt\"].apply(clean_dollar)\n",
        "users_data[\"per_capita_income\"] = users_data[\"per_capita_income\"].apply(clean_dollar)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NewxL1AUex9d",
        "outputId": "dbcd091c-4e07-40e5-dcff-f0d240cc0250"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4221679215.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  cards_data[\"acct_open_date\"] = pd.to_datetime(cards_data[\"acct_open_date\"], errors=\"coerce\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Fusion des datasets"
      ],
      "metadata": {
        "id": "VKZmF7vveyEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_merged = transactions_train.merge(labels_df, on=\"transaction_id\", how=\"left\")\n",
        "\n",
        "merged = (\n",
        "    train_merged\n",
        "    .merge(cards_data, left_on=\"card_id\", right_on=\"id\", how=\"left\", suffixes=(\"\", \"_card\"))\n",
        "    .merge(users_data, left_on=\"client_id\", right_on=\"id\", how=\"left\", suffixes=(\"\", \"_user\"))\n",
        "    .merge(mcc_df, on=\"mcc\", how=\"left\")\n",
        ")\n",
        "\n",
        "print(\"Fusion réussie :\", merged.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSXSpWnfezN8",
        "outputId": "2572290a-fcd5-4689-ad7d-c14130b229ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fusion réussie : (210000, 41)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Préparation pour Machine Learning"
      ],
      "metadata": {
        "id": "HucTgQxhezUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# On supprime les colonnes inutiles ou non exploitables\n",
        "drop_cols = [\n",
        "    \"transaction_id\", \"date\", \"merchant_city\", \"merchant_state\",\n",
        "    \"address\", \"card_number\", \"acct_open_date\", \"id\", \"id_card\", \"id_user\"\n",
        "]\n",
        "data = merged.drop(columns=[c for c in drop_cols if c in merged.columns], errors=\"ignore\")\n",
        "\n",
        "# Encodage des variables catégorielles\n",
        "cat_cols = data.select_dtypes(include=[\"object\"]).columns\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col].astype(str))\n",
        "\n",
        "# Suppression des lignes sans label\n",
        "data = data.dropna(subset=[\"fraud_label\"])\n",
        "\n",
        "# Séparation X / y\n",
        "X = data.drop(columns=[\"fraud_label\"])\n",
        "y = data[\"fraud_label\"].astype(int)\n",
        "\n",
        "# Normalisation\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"✅ Dataset prêt pour entraînement\")\n",
        "print(\"X_train :\", X_train.shape, \"| y_train :\", y_train.shape)\n",
        "print(\"Taux de fraude dans le train :\", round(y_train.mean()*100, 5), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeThYMpbe-Pe",
        "outputId": "c79976c8-364a-433e-d8f4-75bc8e66566a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset prêt pour entraînement\n",
            "X_train : (168000, 31) | y_train : (168000,)\n",
            "Taux de fraude dans le train : 0.15 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "QfXFURJ6fSuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# --- Entraînement ---\n",
        "log_reg = LogisticRegression(\n",
        "    class_weight='balanced',  # corrige le déséquilibre des classes\n",
        "    max_iter=500,\n",
        "    solver='liblinear',       # bon pour datasets déséquilibrés\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# --- Prédictions ---\n",
        "y_pred = log_reg.predict(X_test)\n",
        "y_proba = log_reg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# --- Évaluation ---\n",
        "print(\"✅ Évaluation du modèle Logistique\")\n",
        "print(\"Matrice de confusion :\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nRapport de classification :\\n\", classification_report(y_test, y_pred, digits=4))\n",
        "print(\"ROC-AUC :\", round(roc_auc_score(y_test, y_proba), 5))\n",
        "auprc = average_precision_score(y_test, y_proba)\n",
        "print(\"AUPRC :\", round(auprc, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK24PyJKPkdn",
        "outputId": "fb6ee91a-0d33-4a45-fa33-422dc4bd863d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Évaluation du modèle Logistique\n",
            "Matrice de confusion :\n",
            " [[36301  5636]\n",
            " [   17    46]]\n",
            "\n",
            "Rapport de classification :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9995    0.8656    0.9278     41937\n",
            "           1     0.0081    0.7302    0.0160        63\n",
            "\n",
            "    accuracy                         0.8654     42000\n",
            "   macro avg     0.5038    0.7979    0.4719     42000\n",
            "weighted avg     0.9980    0.8654    0.9264     42000\n",
            "\n",
            "ROC-AUC : 0.88729\n",
            "AUPRC : 0.03009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Classifier"
      ],
      "metadata": {
        "id": "TLbtkRR8fVpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# --- Entraînement ---\n",
        "model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=50,  # car très peu de fraudes (~0.15%)\n",
        "    eval_metric='logloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# --- Évaluation ---\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"✅ Évaluation du modèle\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "print(\"ROC-AUC :\", round(roc_auc_score(y_test, y_proba), 5))\n",
        "auprc = average_precision_score(y_test, y_proba)\n",
        "print(\"AUPRC :\", round(auprc, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSWFr2ryOqS6",
        "outputId": "330d8555-929f-46d8-bc62-4dfda29bb914"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Évaluation du modèle\n",
            "[[41918    19]\n",
            " [   37    26]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9991    0.9995    0.9993     41937\n",
            "           1     0.5778    0.4127    0.4815        63\n",
            "\n",
            "    accuracy                         0.9987     42000\n",
            "   macro avg     0.7884    0.7061    0.7404     42000\n",
            "weighted avg     0.9985    0.9987    0.9986     42000\n",
            "\n",
            "ROC-AUC : 0.96362\n",
            "AUPRC : 0.43537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CatBoost Classifier"
      ],
      "metadata": {
        "id": "qdaUQ2XrfX5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "9aK-zgjLaAX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740716f7-6b37-4462-80e6-db8e015d0f65"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# --- Entraînement ---\n",
        "cat_model = CatBoostClassifier(\n",
        "    iterations=1000,            # nombre d'arbres\n",
        "    depth=8,                    # profondeur de chaque arbre\n",
        "    learning_rate=0.05,         # taux d'apprentissage\n",
        "    loss_function='Logloss',\n",
        "    eval_metric='AUC',\n",
        "    class_weights=[1, 500],     # fort déséquilibre de classes (~0.15%)\n",
        "    random_seed=42,\n",
        "    verbose=200,                # affiche la progression\n",
        "    task_type=\"CPU\"             # passe à \"GPU\" si tu en as un\n",
        ")\n",
        "\n",
        "cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), use_best_model=True)\n",
        "\n",
        "# --- Évaluation ---\n",
        "y_pred = cat_model.predict(X_test)\n",
        "y_proba = cat_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\n✅ Évaluation du modèle CatBoost\")\n",
        "print(\"Matrice de confusion :\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nRapport de classification :\\n\", classification_report(y_test, y_pred, digits=4))\n",
        "print(\"ROC-AUC :\", round(roc_auc_score(y_test, y_proba), 5))\n",
        "auprc = average_precision_score(y_test, y_proba)\n",
        "print(\"AUPRC :\", round(auprc, 5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt-_lGp5ZCbN",
        "outputId": "b789dea1-a8ff-48ba-bfcc-14124a9c819d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\ttest: 0.9141318\tbest: 0.9141318 (0)\ttotal: 536ms\tremaining: 8m 55s\n",
            "200:\ttest: 0.9664096\tbest: 0.9667975 (187)\ttotal: 27.2s\tremaining: 1m 48s\n",
            "400:\ttest: 0.9710212\tbest: 0.9710352 (352)\ttotal: 36.5s\tremaining: 54.6s\n",
            "600:\ttest: 0.9710212\tbest: 0.9710352 (352)\ttotal: 44.8s\tremaining: 29.7s\n",
            "800:\ttest: 0.9710212\tbest: 0.9710352 (352)\ttotal: 52.3s\tremaining: 13s\n",
            "999:\ttest: 0.9710212\tbest: 0.9710352 (352)\ttotal: 1m\tremaining: 0us\n",
            "\n",
            "bestTest = 0.971035162\n",
            "bestIteration = 352\n",
            "\n",
            "Shrink model to first 353 iterations.\n",
            "\n",
            "✅ Évaluation du modèle CatBoost\n",
            "Matrice de confusion :\n",
            " [[41880    57]\n",
            " [   36    27]]\n",
            "\n",
            "Rapport de classification :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9991    0.9986    0.9989     41937\n",
            "           1     0.3214    0.4286    0.3673        63\n",
            "\n",
            "    accuracy                         0.9978     42000\n",
            "   macro avg     0.6603    0.7136    0.6831     42000\n",
            "weighted avg     0.9981    0.9978    0.9979     42000\n",
            "\n",
            "ROC-AUC : 0.97104\n",
            "AUPRC : 0.40438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM"
      ],
      "metadata": {
        "id": "ajAGyiEEelxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score\n",
        "\n",
        "# --- Entraînement ---\n",
        "lgb_model = lgb.LGBMClassifier(\n",
        "    n_estimators=1000,          # nombre d'arbres\n",
        "    learning_rate=0.03,         # taux d'apprentissage\n",
        "    num_leaves=64,              # complexité des arbres\n",
        "    max_depth=-1,               # -1 = pas de limite de profondeur\n",
        "    subsample=0.8,              # échantillonnage pour éviter l'overfitting\n",
        "    colsample_bytree=0.8,\n",
        "    objective='binary',\n",
        "    class_weight='balanced',    # gère le déséquilibre\n",
        "    random_state=42,\n",
        "    n_jobs=-1                   # exploitation multi-core\n",
        ")\n",
        "\n",
        "lgb_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    eval_metric='auc',\n",
        ")\n",
        "\n",
        "# --- Évaluation ---\n",
        "y_pred = lgb_model.predict(X_test)\n",
        "y_proba = lgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\n✅ Évaluation du modèle LightGBM\")\n",
        "print(\"Matrice de confusion :\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nRapport de classification :\\n\", classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "auroc = roc_auc_score(y_test, y_proba)\n",
        "auprc = average_precision_score(y_test, y_proba)\n",
        "print(f\"ROC-AUC : {auroc:.5f}\")\n",
        "print(f\"AUPRC   : {auprc:.5f}\")"
      ],
      "metadata": {
        "id": "PLow3zgplmE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6044a10c-6cee-432e-f6ff-d4388ce54caa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 252, number of negative: 167748\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059844 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4101\n",
            "[LightGBM] [Info] Number of data points in the train set: 168000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Évaluation du modèle LightGBM\n",
            "Matrice de confusion :\n",
            " [[41931     6]\n",
            " [   40    23]]\n",
            "\n",
            "Rapport de classification :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9990    0.9999    0.9995     41937\n",
            "           1     0.7931    0.3651    0.5000        63\n",
            "\n",
            "    accuracy                         0.9989     42000\n",
            "   macro avg     0.8961    0.6825    0.7497     42000\n",
            "weighted avg     0.9987    0.9989    0.9987     42000\n",
            "\n",
            "ROC-AUC : 0.97350\n",
            "AUPRC   : 0.54938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oYf9GwLIeBQt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}